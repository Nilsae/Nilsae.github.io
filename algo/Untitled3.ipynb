{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_of_medians(A, i):\n",
    "    #divide A into sublists of len 5\n",
    "    sublists = [A[j:j+5] for j in range(0, len(A), 5)]\n",
    "    medians = [sorted(sublist)[int(len(sublist)/2)] for sublist in sublists]\n",
    "    if len(medians) <= 5:\n",
    "        pivot = sorted(medians)[int(len(medians)/2)]\n",
    "    else:\n",
    "        #the pivot is the median of the medians\n",
    "        pivot = median_of_medians(medians, int(len(medians)/2))\n",
    "\n",
    "    #partitioning step\n",
    "    low = [j for j in A if j < pivot]\n",
    "    high = [j for j in A if j > pivot]\n",
    "\n",
    "    k = len(low)\n",
    "    if i < k:\n",
    "        return median_of_medians(low,i)\n",
    "    elif i > k:\n",
    "        return median_of_medians(high,i-k-1)\n",
    "    else: #pivot = k\n",
    "        return pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=[25,21,98,100,76,22,43,60,89,87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MED_INDX=int(len(A)/2-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "print(median_of_medians(A,MED_INDX))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median-of-medians Algorithm\n",
    "\n",
    "The algorithm takes in a list and an index—median-of-medians(A, i). Assume that all elements of AA are distinct (though the algorithm can be further generalized to allow for duplicate elements).\n",
    "\n",
    "Divide the list into sublists each of length five (if there are fewer than five elements available for the last list, that is fine).\n",
    "\n",
    "Sort each sublist and determine the median. Sorting very small lists takes linear time since these sublists have five elements, and this takes O(n)O(n) time. In the algorithm described on this page, if the list has an even number of elements, take the floor of the length of the list divided by 2 to find the index of the median.\n",
    "\n",
    "Use the median-of-median algorithm to recursively determine the median of the set of all the medians.\n",
    "\n",
    "Use this median as the pivot element, xx. The pivot is an approximate median of the whole list and then each recursive step hones in on the true median.\n",
    "\n",
    "Reorder AA such that all elements less than xx are to the left of xx, and all elements of AA that are greater than xx are to the right. This is called partitioning. The elements are in no particular order once they are placed on either side of xx. For example, if xx is 5,5, the list to the right of xx maybe look like  [8,7,12,6] (i.e. not in sorted order). This takes linear time since O(n)O(n) comparisons occur—each element in AA is compared against xx only.\n",
    "\n",
    "\n",
    "\n",
    "6. Let kk be the “rank” of x,x, meaning, for a set of numbers S,S, xx is the k^\\text{th}k \n",
    "th\n",
    "  smallest number in SS.\n",
    "\n",
    "7a. If i = ki=k, then return xx.\n",
    "7b. If i < ki<k, then recurse using median-of-medians on (A[1, \\ldots, k-1], i)(A[1,…,k−1],i).\n",
    "7c. If i >ki>k, recurse using the median-of-medians algorithm on (A[k+1, \\ldots, i ], i-k)(A[k+1,…,i],i−k)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A=[25,21,98,100,76,22,43,60,89,87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \n",
    "1\n",
    "​\t\n",
    " =[21,25,76,98,100] and A \n",
    "2\n",
    "​\t\n",
    " =[22,43,60,87,89].\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M=[60,76]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76 -> A’=[25,22,43,60,21,76,100,89,87,98].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60 -> A’=[25,22,43,21,60,76,100,89,87,98].\n",
    "\n",
    "[76,87,89,98,100]\n",
    "\n",
    "->0->76\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTBST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the OptBST algorithm is modified to cache the roots that determine the\n",
    "recurrence values for each subproblem (i.e., the value of r such that A[i][i + s] =\n",
    "A[i][r-1] + A[r + 1][i + s]), the reconstruction algorithm runs in O(n) time (as\n",
    "you should verify). Otherwise, it must recompute these roots and runs in O(n 2 )\n",
    "time.\n",
    "P\n",
    "19\n",
    "Here’s the idea. First, compute in advance all sums of the form jk=i p k ;\n",
    "2\n",
    "this can be done in O(n ) time (do you see how?). Then, along with each\n",
    "subproblem solution A[i][j], store the choice of the root r(i, j) that minimizes\n",
    "A[i][r-1] + A[r + 1][j] or, equivalently, the root of an optimal search tree for the\n",
    "subproblem. (If there are multiple such roots, use the smallest one.)\n",
    "The key lemma is an easy-to-believe (but tricky-to-prove) monotonicity property:\n",
    "Adding a new maximum (respectively, minimum) element to a subproblem can only\n",
    "make the root of an optimal search tree larger (respectively, smaller). Intuitively,\n",
    "any change in the root should be in service of rebalancing the total frequency of\n",
    "keys between its left and right subtrees.\n",
    "Assuming this lemma, for every subproblem with i < j, the optimal root r(i, j)\n",
    "is at least r(i, j-1) and at most r(i + 1, j). (If i = j, then r(i, j) must be i.)\n",
    "Thus, there’s no point in exhaustively searching all the roots between i and j—the\n",
    "roots between r(i, j 1) and r(i + 1, j) suffice. In the worst case, there could be\n",
    "as many as n such roots. In aggregate\n",
    "all ⇥(n 2 ) subproblems, however, the\n",
    "P n 1 P over\n",
    "n\n",
    "number of roots examined is i=1\n",
    "r(i, j 1) + 1), which\n",
    "j=i+1 (r(i + 1, j)\n",
    "after cancellations is only O(n 2 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A=[25,21,98,100,76,22,43,60,89,87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google uses an interesting 'spell-checking' algorithm with a quite high accuracy. Google uses masses of data for Natural Language Processing (NLP). Spelling correction is an application of NLP. This algorithm needs data preparation from large chunks of data because it evaluates the most used words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word searching works by defining the edit distance. Edit distance means how many recent most popular words, related to search, needs to be evaluated. If edit distance is 0-2, then most recent 2 words will be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google splelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'big.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-0dfd04da799a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\w+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mWORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'big.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORDS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'big.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('big.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-415d4e69868a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'speling'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m'spelling'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'korrectud'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m'corrected'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'correction' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    ">>> correction('speling')\n",
    "'spelling'\n",
    "\n",
    ">>> correction('korrectud')\n",
    "'corrected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
